import streamlit as st
import azure.cognitiveservices.speech as speechsdk
import os
import uuid
import json
import pandas as pd
import string

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIè‹±èªç™ºéŸ³ã‚³ãƒ¼ãƒ", page_icon="ğŸ—£ï¸")

# --- CSSå®šç¾© ---
st.markdown("""
<style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    .correction-box {
        font-family: "Helvetica Neue", Arial, sans-serif;
        line-height: 2.5;
        font-size: 22px;
        background-color: #f8f9fa;
        padding: 20px;
        border-radius: 12px;
        border: 2px solid #e9ecef;
        margin-bottom: 20px;
    }
    
    .word-green { color: #28a745; font-weight: bold; margin-right: 5px; }
    .word-yellow { color: #d39e00; font-weight: bold; margin-right: 5px; }
    .word-red { color: #dc3545; font-weight: bold; margin-right: 5px; text-decoration: underline; text-decoration-style: dotted; }
    .word-omission { color: #adb5bd; text-decoration: line-through; margin-right: 5px; }
    
    /* æŒ¿å…¥ï¼ˆç´«ï¼‰ */
    .word-insertion { color: #6f42c1; font-weight: bold; font-style: italic; margin-left: 2px; margin-right: 8px; }
    
    /* ã‚´ãƒ¼ã‚¹ãƒˆå˜èªï¼ˆAIãŒç„¡è¦–ã—ãŸãŒèãå–ã‚ŒãŸå˜èªï¼‰ */
    .word-ghost { 
        color: #fff; 
        background-color: #6f42c1; 
        padding: 2px 6px; 
        border-radius: 4px; 
        font-size: 0.8em;
        margin-left: 5px;
        vertical-align: middle;
    }
</style>
""", unsafe_allow_html=True)

# --- è¨­å®š ---
try:
    SPEECH_KEY = st.secrets["SPEECH_KEY"]
    SPEECH_REGION = st.secrets["SPEECH_REGION"]
except:
    st.error("è¨­å®šã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

if 'user_id' not in st.session_state:
    st.session_state.user_id = str(uuid.uuid4())

def get_filename(base_name):
    return f"{base_name}_{st.session_state.user_id}.wav"

def get_speech_synthesizer():
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    speech_config.speech_synthesis_voice_name = "en-US-JennyNeural" 
    return speech_config

def normalize_word(w):
    # å¥èª­ç‚¹é™¤å»ã¨å°æ–‡å­—åŒ–
    return w.lower().translate(str.maketrans('', '', string.punctuation))

def assess_pronunciation(audio_file_path, reference_text):
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    speech_config.speech_recognition_language = "en-US" 
    
    # 1. æ¡ç‚¹ç”¨
    audio_config_score = speechsdk.audio.AudioConfig(filename=audio_file_path)
    pronunciation_config = speechsdk.PronunciationAssessmentConfig(
        reference_text=reference_text,
        grading_system=speechsdk.PronunciationAssessmentGradingSystem.HundredMark,
        granularity=speechsdk.PronunciationAssessmentGranularity.Phoneme
    )
    pronunciation_config.enable_miscue = True 

    recognizer_score = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config_score)
    pronunciation_config.apply_to(recognizer_score)
    result_score = recognizer_score.recognize_once_async().get()

    # 2. èãå–ã‚Šç”¨
    audio_config_raw = speechsdk.audio.AudioConfig(filename=audio_file_path)
    recognizer_raw = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config_raw)
    result_raw = recognizer_raw.recognize_once_async().get()

    json_result_str = result_score.json
    raw_transcription = result_raw.text if result_raw.reason == speechsdk.ResultReason.RecognizedSpeech else ""

    return json_result_str, raw_transcription, result_score

def generate_tts(text, filename):
    speech_config = get_speech_synthesizer()
    audio_config = speechsdk.audio.AudioConfig(filename=filename)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
    result = synthesizer.speak_text_async(text).get()
    return result

# --- UI ---
st.title("ğŸ—£ï¸ AIè‹±èªç™ºéŸ³ã‚³ãƒ¼ãƒ")
st.info("AIãŒç„¡è¦–ã—ãŸå˜èªã‚‚ã€Œèãå–ã‚Šãƒ†ã‚­ã‚¹ãƒˆã€ã‹ã‚‰å¼·åˆ¶çš„ã«æ‹¾ã„ä¸Šã’ã‚‹æ©Ÿèƒ½ã‚’æ­è¼‰ã—ã¾ã—ãŸã€‚")

if 'target_text' not in st.session_state:
    st.session_state.target_text = "I like playing soccer with my friends."

target_text = st.text_area("èª­ã‚€è‹±æ–‡ã‚’å…¥åŠ›:", st.session_state.target_text, key="input_text")

st.markdown("##### ã‚¹ãƒ†ãƒƒãƒ—1ï¼šãŠæ‰‹æœ¬ã‚’ç¢ºèªã™ã‚‹")
if st.button("ğŸ”Š ãŠæ‰‹æœ¬ã‚’èã"):
    with st.spinner("éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
        tts_file = get_filename("model_reference")
        generate_tts(target_text, tts_file)
        st.audio(tts_file, format="audio/wav")

st.divider()

st.markdown("##### ã‚¹ãƒ†ãƒƒãƒ—2ï¼šéŒ²éŸ³ã—ã¦æ¡ç‚¹")
audio_value = st.audio_input("éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦å…¨æ–‡ã‚’èª­ã‚€")

if audio_value:
    input_filename = get_filename("temp_input")
    with open(input_filename, "wb") as f:
        f.write(audio_value.getbuffer())

    with st.spinner("AIãŒåˆ†æä¸­..."):
        json_str, raw_text_heard, result_obj = assess_pronunciation(input_filename, target_text)

    if result_obj.reason == speechsdk.ResultReason.RecognizedSpeech:
        data = json.loads(json_str)
        
        if 'NBest' in data and len(data['NBest']) > 0:
            nbest = data['NBest'][0]
            words_data = nbest.get('Words', [])
            
            pron_scores = nbest.get('PronunciationAssessment', {})
            acc = pron_scores.get('AccuracyScore', 0)
            flu = pron_scores.get('FluencyScore', 0)
            com = pron_scores.get('CompletenessScore', 0)

            total_words_for_score = 0
            green_count = 0
            weak_words = []
            feedback_html_parts = []
            debug_table_data = []

            # å‡¦ç†æ¸ˆã¿å˜èªã®è¿½è·¡ç”¨ï¼ˆGhoståˆ¤å®šã«ä½¿ç”¨ï¼‰
            processed_words_norm = []

            if not words_data:
                st.warning("å˜èªãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                # --- é€šå¸¸ã®ãƒ«ãƒ¼ãƒ—å‡¦ç† ---
                for word_info in words_data:
                    word_text = word_info.get('Word') or word_info.get('DisplayWord') or "???"
                    processed_words_norm.append(normalize_word(word_text))
                    
                    pron_acc = word_info.get('PronunciationAssessment', {})
                    raw_error_type = pron_acc.get('ErrorType') or word_info.get('ErrorType') or 'None'
                    accuracy = pron_acc.get('AccuracyScore', 0)
                    
                    # 1. æŒ¿å…¥
                    if raw_error_type.lower() == "insertion":
                        final_error_type = "Insertion (ç´«)"
                        feedback_html_parts.append(f"<span class='word-insertion'>({word_text})</span>")
                    
                    # 2. èª­ã¿é£›ã°ã—
                    elif raw_error_type == "Omission":
                        total_words_for_score += 1
                        weak_words.append(word_text)
                        final_error_type = "Omission (ç°)"
                        feedback_html_parts.append(f"<span class='word-omission'>{word_text}</span>")
                    
                    # 3. ä½ã‚¹ã‚³ã‚¢è¶³åˆ‡ã‚Š
                    elif raw_error_type == "Mispronunciation" and accuracy <= 40:
                        total_words_for_score += 1
                        weak_words.append(word_text)
                        final_error_type = "Low Score -> Omission (ç°)"
                        feedback_html_parts.append(f"<span class='word-omission'>{word_text}</span>")
                    
                    # 4. é€šå¸¸
                    else:
                        total_words_for_score += 1
                        if accuracy >= 85:
                            css_class = "word-green"
                            final_error_type = "Excellent (ç·‘)"
                            green_count += 1
                        elif accuracy >= 75:
                            css_class = "word-yellow"
                            final_error_type = "Good (é»„)"
                            weak_words.append(word_text)
                        else:
                            css_class = "word-red"
                            final_error_type = "Bad (èµ¤)"
                            weak_words.append(word_text)
                        
                        feedback_html_parts.append(f"<span class='{css_class}' title='{accuracy}ç‚¹'>{word_text}</span>")

                    debug_table_data.append({
                        "å˜èª": word_text,
                        "AIåˆ¤å®š (Raw)": raw_error_type,
                        "ã‚¹ã‚³ã‚¢": accuracy,
                        "æœ€çµ‚è¡¨ç¤º": final_error_type
                    })

                # --- â˜…â˜…â˜… ã‚´ãƒ¼ã‚¹ãƒˆå˜èªï¼ˆAIç„¡è¦–å˜èªï¼‰ã®æ•‘æ¸ˆãƒ­ã‚¸ãƒƒã‚¯ â˜…â˜…â˜… ---
                # èãå–ã£ãŸå…¨å˜èªã‚’å–å¾—
                raw_words = raw_text_heard.split()
                target_words_norm = [normalize_word(w) for w in target_text.split()]
                
                ghost_words_found = []
                
                for raw_w in raw_words:
                    r_norm = normalize_word(raw_w)
                    # ã€Œèãå–ã‚ŒãŸå˜èªã€ãŒã€Œã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ–‡ã€ã«ã‚‚ã€Œå‡¦ç†æ¸ˆã¿ãƒªã‚¹ãƒˆï¼ˆæŒ¿å…¥å«ã‚€ï¼‰ã€ã«ã‚‚ãªã„å ´åˆ
                    # â€» ç°¡æ˜“çš„ãªåˆ¤å®šã®ãŸã‚ã€é‡è¤‡ã‚„èªé †ã§èª¤æ¤œçŸ¥ã™ã‚‹å¯èƒ½æ€§ã¯ã‚ã‚‹ãŒã€è¡¨ç¤ºã•ã‚Œãªã„ã‚ˆã‚Šãƒã‚·ã¨ã„ã†åˆ¤æ–­
                    if r_norm not in target_words_norm and r_norm not in processed_words_norm:
                        ghost_words_found.append(raw_w)
                        # é‡è¤‡è¿½åŠ ã‚’é˜²ããŸã‚å‡¦ç†æ¸ˆã¿ã«åŠ ãˆã‚‹
                        processed_words_norm.append(r_norm)

                if ghost_words_found:
                    for gw in ghost_words_found:
                        # ç”»é¢è¡¨ç¤ºã«è¿½åŠ 
                        feedback_html_parts.append(f"<span class='word-ghost'>Ghost: {gw}</span>")
                        # è¨ºæ–­ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¿½åŠ 
                        debug_table_data.append({
                            "å˜èª": gw,
                            "AIåˆ¤å®š (Raw)": "Not in JSON",
                            "ã‚¹ã‚³ã‚¢": "-",
                            "æœ€çµ‚è¡¨ç¤º": "å¼·åˆ¶æ¤œå‡º (ç´«ã‚¿ã‚°)"
                        })

                # --- çµæœè¡¨ç¤ºè¨ˆç®— ---
                if total_words_for_score > 0:
                    green_ratio = (green_count / total_words_for_score) * 100
                else:
                    green_ratio = 0

                if green_ratio >= 85:
                    st.balloons()
                    st.success(f"ğŸ‰ Excellent! (ç·‘ç‡: {green_ratio:.1f}%)")
                elif green_ratio >= 75:
                    st.warning(f"âš ï¸ Good! (ç·‘ç‡: {green_ratio:.1f}%)")
                else:
                    st.error(f"âŒ Try Again. (ç·‘ç‡: {green_ratio:.1f}%)")

                c1, c2, c3 = st.columns(3)
                c1.metric("Accuracy", f"{acc:.0f}")
                c2.metric("Fluency", f"{flu:.0f}")
                c3.metric("Completeness", f"{com:.0f}")

                st.divider()

                st.subheader("ğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ")
                st.markdown("##### ğŸ‘‚ èãå–ã‚Šå†…å®¹ (Raw Text)")
                st.info(f"ã€Œ {raw_text_heard} ã€")

                st.markdown("##### ğŸ“Š æ·»å‰Šçµæœ")
                final_html = "".join(feedback_html_parts)
                st.markdown(f"<div class='correction-box'>{final_html}</div>", unsafe_allow_html=True)
                st.caption("å‡¡ä¾‹: ğŸŸ¢OK ğŸ”´NG ğŸ”˜å–ã‚Šæ¶ˆã—ç·š(èª­ã¿é£›ã°ã—) ğŸŸ£(é€šå¸¸ã®æŒ¿å…¥) ğŸ†ã‚¿ã‚°(AIãŒç„¡è¦–ã—ãŸæŒ¿å…¥èª)")

                st.markdown("---")
                st.subheader("ğŸ§ åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯è¨ºæ–­ãƒ†ãƒ¼ãƒ–ãƒ«")
                st.dataframe(pd.DataFrame(debug_table_data))

                st.divider()

                # --- å¼±ç‚¹ç‰¹è¨“ ---
                if len(weak_words) > 0:
                    st.subheader("ğŸ”¥ å¼±ç‚¹ç‰¹è¨“ã‚³ãƒ¼ãƒŠãƒ¼")
                    unique_weak_words = [w for w in list(dict.fromkeys(weak_words)) if w != "???"]
                    if unique_weak_words:
                        selected_word = st.selectbox("ç·´ç¿’ã™ã‚‹å˜èª:", unique_weak_words)
                        ca, cb = st.columns(2)
                        with ca:
                            if st.button(f"Play: {selected_word}"):
                                tts_s = get_filename("single_word_tts")
                                generate_tts(selected_word, tts_s)
                                st.audio(tts_s)
                        with cb:
                            pa = st.audio_input(f"Record: {selected_word}", key="p_rec")
                            if pa:
                                pf = get_filename("practice")
                                with open(pf, "wb") as f: f.write(pa.getbuffer())
                                _, _, pr = assess_pronunciation(pf, selected_word)
                                if pr.reason == speechsdk.ResultReason.RecognizedSpeech:
                                    s = speechsdk.PronunciationAssessmentResult(pr).accuracy_score
                                    if s >= 85: st.success(f"ğŸ‰ {s:.0f}ç‚¹")
                                    elif s >= 75: st.warning(f"ğŸŸ¡ {s:.0f}ç‚¹")
                                    else: st.error(f"ğŸ”´ {s:.0f}ç‚¹")
        else:
            st.error("è§£æå¤±æ•—")
            
        with st.expander("ğŸ› ï¸ é–‹ç™ºç”¨ãƒ‡ãƒ¼ã‚¿ç¢ºèª (Raw JSON)"):
            st.json(json.loads(json_str))

    elif result_obj.reason == speechsdk.ResultReason.NoMatch:
        st.error("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    elif result_obj.reason == speechsdk.ResultReason.Canceled:
        st.error("å‡¦ç†ä¸­æ–­ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
